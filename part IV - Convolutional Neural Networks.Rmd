---
title: "part IV - Convolutional Neural Networks"
author: "Micha≈Ç Maj"
output: html_notebook
---

```{r packages}
library(keras)
library(tidyverse)
library(grid)
library(gridExtra)
```

Before we will build CNN in keras we have to understand convolution and pooling. Load the "data/zebra.jpg" image

```{r image_load}
zebra <- image_load("data/zebra.jpg", grayscale = TRUE, target_size = c(200, 300)) %>%
  image_to_array() %>% `/`(255)
image(t(zebra[, , 1])[, nrow(zebra):1], col = grey(seq(0, 1, length = 256)), axes = F)
```

Now we can implement some simple convolution:

```{r 2d_convolution}
sobel_filter_x <- matrix(c(1, 2, 1, 0, 0, 0, -1, -2, -1), 3, 3, byrow = FALSE)

kernel_shape <- 3
padding <- 0
stride <- 1
input_height <- nrow(zebra)
input_width <- ncol(zebra)
activation_map_height <- (input_height + 2 * padding - kernel_shape) / stride + 1
activation_map_width <- (input_width + 2 * padding - kernel_shape) / stride + 1
activation_map <- matrix(0, nrow = activation_map_height, ncol = activation_map_width)

for (w in 1:ncol(activation_map)) {
  for (h in 1:nrow(activation_map)) {
    activation_map[h, w] <- sum(sobel_filter_x * zebra[h:(h + kernel_shape - 1), w:(w + kernel_shape - 1), 1])
  }
}

image(t(activation_map)[, nrow(activation_map):1], col = grey(seq(0, 1, length = 256)), axes = F)
```

And max pooling:

```{r 2d_max_pooling}
pool_shape <- 2
pool_stride <- 2
activation_map2_height <- activation_map_height / pool_shape
activation_map2_width <- activation_map_width / pool_shape
activation_map2 <- matrix(0, nrow = activation_map2_height, ncol = activation_map2_width)

for (w in 1:ncol(activation_map2)) {
  for (h in 1:nrow(activation_map2)) {
    activation_map2[h, w] <- max(activation_map[(2 * (h - 1) + 1):((2 * (h - 1) + 1) + pool_shape - 1), (2 * (w - 1) + 1):((2 * (w - 1) + 1) + pool_shape - 1)])
  }
}

image(t(activation_map2)[, nrow(activation_map2):1], col = grey(seq(0, 1, length = 256)), axes = F)
```

We will start by building simple CNN for fashion mnist dataset. In the first meeting we created an MLP for this task. Let's load the dataset:

```{r fashion_mnist}
load("data/fashion_mnist.RData")
xy_axis <- data.frame(x = expand.grid(1:28, 28:1)[, 1],
                      y = expand.grid(1:28, 28:1)[, 2])
plot_theme <- list(
  raster = geom_raster(hjust = 0, vjust = 0),
  gradient_fill = scale_fill_gradient(low = "white", high = "black", guide = FALSE),
  theme = theme_void()
)

sample_plots <- sample(1:nrow(fashion_mnist_train_X), 100) %>% map(~ {
  plot_data <- cbind(xy_axis, fill = data.frame(fill = fashion_mnist_train_X[.x, ]))
  ggplot(plot_data, aes(x, y, fill = fill)) + plot_theme
})

do.call("grid.arrange", c(sample_plots, ncol = 10, nrow = 10))
```

In order to insert data into keras CNN model we have to reshape our data into proper tensors. As in the case of MLP we have to transform labels vector into on-hot-encding matrix. In case of our images we have to represent them as a 4-dimmentional tensor (samples, height, width, channels). We also have to remember to normalize pixel values:

```{r fashion_mnist_data}
fashion_mnist_train_Y <- fashion_mnist_train_Y %>% to_categorical(., 10)
fashion_mnist_test_Y <- fashion_mnist_test_Y %>% to_categorical(., 10)

fashion_mnist_train_X <- fashion_mnist_train_X / 255
fashion_mnist_test_X <- fashion_mnist_test_X / 255

fashion_mnist_train_X <- array_reshape(fashion_mnist_train_X, c(nrow(fashion_mnist_train_X), 28, 28, 1))
fashion_mnist_test_X <- array_reshape(fashion_mnist_test_X, c(nrow(fashion_mnist_test_X), 28, 28, 1))

dim(fashion_mnist_train_X)
```

The data is in correct tensor form, we can start building a model. As always it will be a sequential model. As our first layer we will use convolutional layer:

```{r fashion_mnist_conv_layer}
fmnist_model1 <- keras_model_sequential() %>%
  # 2D convolution, 32 filters of size 3x3, input c(28, 28, 1) - grayscale
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = 'relu',
                input_shape = c(28, 28, 1))
fmnist_model1
```

Why do we have 320 parameters to train?

```{r fashion_mnist_conv_layer_params}
32 * (3 * 3 * 1 + 1) # 32 filters of size 3x3(x1) + bias for each of them
```

Why output shape looks like (None, 26, 26, 32) ? 

```{r fashion_mnist_conv_layer_output_shape}
((28 - 3 + 2 * 0) / 1) + 1 # 28 - input image size, 3 - kernsl size, 0 - padding, 1 - stride
```

After convolutional layer we can add another one. Let's use max pooling layer:

```{r fashion_mnist_max_pool_layer}
fmnist_model1 %>%
  # 2D max pooling size 2x2(x1)
  layer_max_pooling_2d(pool_size = c(2, 2))
fmnist_model1
```

Why output shape looks like (None, 12, 12, 32) ?

```{r fashion_mnist_max_pool_layer_output_shape}
26 / 2 # 26 - input of the activation map shape, 2 - pool size
```

Let's say that we want to finish our architecture and add output layer. we will do this in the same way as in MLP, but before we can do that we hve to flatten our last activation map into a vector:

```{r fashion_mnist_output_layer}
fmnist_model1 %>%
  # Tensor flattening into vector form
  layer_flatten() %>%
  # Output layer - 10 classes, softmax activation
  layer_dense(units = 10, activation = 'softmax')

fmnist_model1
```

Why output shape looks like in layer_flatten (None, 5408) ?

```{r fashion_mnist_flatten_layer_output_shape}
13 * 13 * 32 # Check dimmentions of previous layer
```

Why do we have 54090 parameters to train in output layer ?

```{r fashion_mnist_output_layer_output_shape}
5408 * 10 + 10 # 5408 - from layer_flatten * 10 neurons + biases
```

Architerture of CNN is finished, we can now compile the model:

```{r fashion_mnist_compile}
fmnist_model1 %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)
```

Train it:

```{r fashion_mnist_fit}
history <- fmnist_model1 %>% fit(
  fashion_mnist_train_X,
  fashion_mnist_train_Y,
  batch_size = 128,
  epochs = 30,
  validation_split = 0.2,
  callbacks = c(callback_model_checkpoint(monitor = "val_accuracy",
                                          filepath = "models/fmnist_model1.hdf5",
                                          save_best_only = TRUE))
) 
```

And evaluate on test set:

```{r fashion_mnist_evaluate}
fmnist_model1 %>% evaluate(fashion_mnist_test_X, fashion_mnist_test_Y)
```

Now it's time for you to create more advanced version of this model:

```{r fashion_mnist_ex}
# Ex. Expand model by adding batch normalization. Add early stopping and Tensorboard callbacks.
# 1. Model architecture:
# 2D convolution with 64 filters of size 3x3, 1x1 stride, 'linear' activation, "same" padding
# Batch normalization layer
# "relu" activation layer
# 2D max pooling size 2x2, 2x2 stride
# dropout layer with 25% drop rate
# Flattening layer
# dense layer with 512 neurons and "relu" activation
# dropout layer with 25% drop rate
# Choose correct layer as output

# 2. Compile model with Adadelta optimizer - set learning rate 0.01, decay = 1e-6.

# 3. Fit the model - beside standart settings add callbacks:
# model checkpoint - save model as "fmnist_model2.hdf5" in "models" folder
# early stopping - will stop training if there's no progress (monitor "val_accuracy" and don't wait more than 5 epochs)
# tensorboard - save logs to tensorboard in "tensorboard" folder - callback_tensorboard

# 4. Evaluate the model on test set
```

